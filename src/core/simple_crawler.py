#!/usr/bin/env python3
"""
ê°„ë‹¨í•˜ê³  ê¹”ë”í•œ ë„¤ì´ë²„ ì‡¼í•‘ í¬ë¡¤ëŸ¬ (v1.1.0)
13ê°œ í•„ë“œ ì™„ë²½ ìˆ˜ì§‘ + DB ì§ì ‘ ì €ì¥
"""

import asyncio
import re
from datetime import datetime
from playwright.async_api import async_playwright
from typing import Optional, List, Dict
import sys
from pathlib import Path
import time

# DB Connector import
sys.path.append(str(Path(__file__).parent.parent.parent))
from src.database.db_connector import DatabaseConnector


class SimpleCrawler:
    """
    ë„¤ì´ë²„ ì‡¼í•‘ ìƒí’ˆ ìˆ˜ì§‘ í¬ë¡¤ëŸ¬
    13ê°œ í•„ë“œ: product_id, category_name, product_name, search_tags,
              price, rating, product_url, thumbnail_url, brand_name,
              discount_rate, review_count, crawled_at, updated_at
    """

    def __init__(self,
                 category_name: str = "ì—¬ì„±ì˜ë¥˜",
                 category_id: str = "10000107",
                 product_count: Optional[int] = None,  # None = ë¬´í•œ
                 headless: bool = False,
                 save_to_db: bool = True):
        self.category_name = category_name
        self.category_id = category_id
        self.product_count = product_count  # Noneì´ë©´ ë¬´í•œ ìˆ˜ì§‘
        self.headless = headless
        self.save_to_db = save_to_db
        self.should_stop = False
        self.products_data = []

        # DB ì—°ê²° (save_to_dbê°€ Trueì¼ ë•Œë§Œ) - ì„¸ì…˜ ìœ ì§€ ë°©ì‹
        self.db = DatabaseConnector() if save_to_db else None
        self.db_connected = False

        # í†µê³„ ì¶”ì 
        self.start_time = None
        self.saved_count = 0  # DB ì €ì¥ ì„±ê³µ
        self.skipped_count = 0  # ì¤‘ë³µ ìŠ¤í‚µ

    async def crawl(self) -> List[Dict]:
        """í¬ë¡¤ë§ ì‹¤í–‰"""
        async with async_playwright() as p:
            browser = await p.firefox.launch(
                headless=self.headless,
                slow_mo=300
            )

            context = await browser.new_context(
                no_viewport=True,
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0",
                locale='ko-KR',
                timezone_id='Asia/Seoul'
            )

            page = await context.new_page()

            try:
                # DB ì—°ê²° (ì„¸ì…˜ ìœ ì§€)
                if self.save_to_db and self.db:
                    try:
                        self.db.connect()
                        self.db_connected = True
                        print("[DB] ì—°ê²° ì„±ê³µ")
                    except Exception as e:
                        print(f"[DB] ì—°ê²° ì‹¤íŒ¨: {str(e)}")
                        self.db_connected = False

                # 1. ë„¤ì´ë²„ ë©”ì¸ â†’ ì‡¼í•‘ ì§„ì…
                print("[1/4] ë„¤ì´ë²„ ë©”ì¸ í˜ì´ì§€ ì ‘ì†...")
                await page.goto('https://www.naver.com')
                await page.wait_for_load_state('domcontentloaded')
                await asyncio.sleep(2)

                # ì‡¼í•‘ í´ë¦­
                print("[2/4] ì‡¼í•‘ ë²„íŠ¼ í´ë¦­...")
                shopping_selector = '#shortcutArea > ul > li:nth-child(4) > a'
                await page.locator(shopping_selector).click(timeout=10000)
                await asyncio.sleep(2)

                # ìƒˆ íƒ­ ì „í™˜
                all_pages = context.pages
                if len(all_pages) > 1:
                    page = all_pages[-1]
                    await page.wait_for_load_state('networkidle')

                # 2. ì¹´í…Œê³ ë¦¬ ì§„ì… (CRAWLING_LESSONS_LEARNED.md ê²€ì¦ëœ ë°©ë²•)
                print(f"[3/4] '{self.category_name}' ì¹´í…Œê³ ë¦¬ ì§„ì…...")
                category_btn = await page.wait_for_selector('button:has-text("ì¹´í…Œê³ ë¦¬")')
                await category_btn.click()
                await asyncio.sleep(2)  # ë©”ë‰´ ì—´ë¦¬ê¸° ëŒ€ê¸°

                # ìš°ì„ ìˆœìœ„ë³„ ì…€ë ‰í„° fallback (ë¬¸ì„œ 1293-1296ì¤„)
                category_elem = None

                # 1ìˆœìœ„: ID ê¸°ë°˜ (â­â­â­â­â­)
                if self.category_id:
                    category_elem = await page.query_selector(f'#cat_layer_item_{self.category_id}')

                # 2ìˆœìœ„: data-id ì†ì„± (â­â­â­â­)
                if not category_elem and self.category_id:
                    category_elem = await page.query_selector(f'[data-id="{self.category_id}"]')

                # 3ìˆœìœ„: data-name ì†ì„± (â­â­â­)
                if not category_elem:
                    category_elem = await page.query_selector(f'a[data-name="{self.category_name}"]')

                if not category_elem:
                    raise Exception(f"ì¹´í…Œê³ ë¦¬ '{self.category_name}' (ID: {self.category_id})ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

                await category_elem.click()
                await asyncio.sleep(3)

                # ìº¡ì°¨ ëŒ€ê¸° (15ì´ˆ ê³ ì •)
                print("\n" + "="*60)
                print("[!] ìº¡ì°¨ í™•ì¸ - 15ì´ˆ ëŒ€ê¸°")
                print("="*60)
                print("ë¸Œë¼ìš°ì €ì—ì„œ ìº¡ì°¨ë¥¼ ìˆ˜ë™ìœ¼ë¡œ í•´ê²°í•´ì£¼ì„¸ìš”")
                print("="*60)
                for i in range(15, 0, -5):
                    print(f"[ëŒ€ê¸°] ë‚¨ì€ ì‹œê°„: {i}ì´ˆ...")
                    await asyncio.sleep(5)
                print("[OK] ëŒ€ê¸° ì™„ë£Œ! í¬ë¡¤ë§ ì‹œì‘...\n")
                await asyncio.sleep(2)

                # 3. ë¬´í•œ ìŠ¤í¬ë¡¤ ìˆ˜ì§‘ ì‹œì‘
                if self.product_count:
                    print(f"[4/4] ìƒí’ˆ {self.product_count}ê°œ ìˆ˜ì§‘ ì‹œì‘...\n")
                else:
                    print(f"[4/4] ë¬´í•œ ìˆ˜ì§‘ ì‹œì‘ (ì¤‘ì§€ ë²„íŠ¼ìœ¼ë¡œ ë©ˆì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...\n")

                # ì‹œì‘ ì‹œê°„ ê¸°ë¡
                self.start_time = time.time()

                # ì´ˆê¸° ë°°ì¹˜ í¬ê¸° ê²°ì • (ì²˜ìŒ ë¡œë“œëœ ê°œìˆ˜)
                initial_links = await page.query_selector_all('a[class*="ProductCard_link"]')
                batch_size = len(initial_links)  # ì²˜ìŒ ë‚˜ì˜¨ ê°œìˆ˜ ê¸°ì¤€
                print(f"\nì´ˆê¸° ìƒí’ˆ ìˆ˜: {batch_size}ê°œ â†’ ë°°ì¹˜ í¬ê¸°ë¡œ ì‚¬ìš©")

                collected_count = 0
                processed_indices = set()  # ì´ë¯¸ ì²˜ë¦¬í•œ ìƒí’ˆ ì¸ë±ìŠ¤ ì¶”ì 
                scroll_count = 0
                batch_num = 0
                max_scroll_attempts = 100  # ìµœëŒ€ ìŠ¤í¬ë¡¤ íšŸìˆ˜

                while scroll_count < max_scroll_attempts:
                    if self.should_stop:
                        break

                    batch_num += 1

                    # í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  ìƒí’ˆ ë§í¬ ê°€ì ¸ì˜¤ê¸°
                    product_links = await page.query_selector_all('a[class*="ProductCard_link"]')
                    current_total = len(product_links)

                    # ì´ë²ˆ ë°°ì¹˜ ë²”ìœ„ ê³„ì‚° (batch_sizeê°œì”© ì²˜ë¦¬)
                    batch_start = len(processed_indices)
                    batch_end = min(batch_start + batch_size, current_total)

                    print(f"\n[ë°°ì¹˜ {batch_num}] ì „ì²´ {current_total}ê°œ ì¤‘ {batch_start+1}~{batch_end}ë²ˆ ì²˜ë¦¬ ({batch_end - batch_start}ê°œ)")

                    # ë°°ì¹˜ ë²”ìœ„ ë‚´ ìƒí’ˆë§Œ ìˆ˜ì§‘
                    for idx in range(batch_start, batch_end):
                        # ëª©í‘œ ê°œìˆ˜ ë„ë‹¬ ì²´í¬
                        if self.product_count and collected_count >= self.product_count:
                            print(f"\nëª©í‘œ ê°œìˆ˜ ë„ë‹¬! {collected_count}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
                            break

                        if self.should_stop:
                            break

                        # ì²« 14ê°œ ìƒí’ˆ ê±´ë„ˆë›°ê¸° (ê´‘ê³ )
                        if idx < 14:
                            processed_indices.add(idx)
                            continue

                        # ì´ë¯¸ ì²˜ë¦¬í•œ ìƒí’ˆì€ ê±´ë„ˆë›°ê¸°
                        if idx in processed_indices:
                            continue

                        processed_indices.add(idx)

                        try:
                            # ìƒí’ˆ í´ë¦­ (ë§¤ë²ˆ ìƒˆë¡œ ì¿¼ë¦¬ - DOM ë³€ê²½ ëŒ€ì‘)
                            fresh_links = await page.query_selector_all('a[class*="ProductCard_link"]')
                            if idx >= len(fresh_links):
                                print(f"[{idx+1}ë²ˆ] ìƒí’ˆ ì¸ë±ìŠ¤ ì´ˆê³¼ - SKIP")
                                continue

                            product = fresh_links[idx]

                            # ğŸš€ ìµœì í™”: í´ë¦­ ì „ ì¤‘ë³µ ì²´í¬
                            if self.save_to_db and self.db and self.db_connected:
                                try:
                                    # URLì—ì„œ product_id ì¶”ì¶œ
                                    product_url = await product.get_attribute('href')
                                    if product_url:
                                        product_id = self.db.extract_product_id(product_url)

                                        # DB ì¤‘ë³µ ì²´í¬
                                        if self.db.is_duplicate_product(product_id, {}):
                                            self.skipped_count += 1
                                            print(f"[{idx+1}ë²ˆ] ì´ë¯¸ DBì— ì¡´ì¬ - SKIP (ID: {product_id[:20]}...)")
                                            continue
                                except Exception as e:
                                    print(f"[{idx+1}ë²ˆ] ì¤‘ë³µ ì²´í¬ ì˜¤ë¥˜: {str(e)[:30]} - ìˆ˜ì§‘ ì§„í–‰")

                            await product.click()
                            await asyncio.sleep(3)  # 2ì´ˆ â†’ 3ì´ˆ (íƒ­ ì—´ë¦¼ ëŒ€ê¸°)

                            # ìƒˆ íƒ­ ì°¾ê¸°
                            all_pages = context.pages
                            if len(all_pages) <= 1:
                                print(f"[{idx+1}ë²ˆ] íƒ­ ì—´ë¦¼ ì‹¤íŒ¨ - SKIP")
                                continue

                            detail_page = all_pages[-1]
                            await detail_page.wait_for_load_state('domcontentloaded')
                            await asyncio.sleep(2)  # 1ì´ˆ â†’ 2ì´ˆ (í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°)

                            # ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘
                            product_data = await self._collect_product_info(detail_page)

                            if product_data and product_data.get('product_name'):
                                self.products_data.append(product_data)
                                collected_count += 1

                                # ë©”ëª¨ë¦¬ ìµœì í™”: 1000ê°œ ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ (ë§ˆì§€ë§‰ 500ê°œë§Œ ìœ ì§€)
                                if len(self.products_data) > 1000:
                                    self.products_data = self.products_data[-500:]

                                # ì¦‰ì‹œ DB ì €ì¥ (ì„¸ì…˜ ìœ ì§€)
                                if self.save_to_db and self.db and self.db_connected:
                                    try:
                                        result = self.db.save_product(self.category_name, product_data)
                                        if result == 'saved':
                                            self.saved_count += 1
                                            product_data['_db_status'] = 'saved'
                                        elif result == 'skipped':
                                            self.skipped_count += 1
                                            product_data['_db_status'] = 'skipped'
                                    except Exception as e:
                                        product_data['_db_status'] = 'error'
                                        print(f"[{collected_count}] DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
                                else:
                                    product_data['_db_status'] = 'none'

                                # ê°„ëµí•œ ì§„í–‰ ë©”ì‹œì§€ë§Œ ì¶œë ¥
                                print(f"ìˆ˜ì§‘ ì¤‘... {collected_count}ê°œ", end='\r')

                                # 50ê°œë§ˆë‹¤ ìƒì„¸ í…Œì´ë¸” ì¶œë ¥
                                if collected_count % 50 == 0:
                                    self._print_products_table(collected_count)
                            else:
                                print(f"[{idx+1}ë²ˆ] ìˆ˜ì§‘ ì‹¤íŒ¨ (ìƒí’ˆëª… ì—†ìŒ) - SKIP")

                            # íƒ­ ë‹«ê¸°
                            await detail_page.close()
                            await asyncio.sleep(1)

                        except Exception as e:
                            print(f"[{idx+1}ë²ˆ] ì˜¤ë¥˜: {str(e)[:50]} - SKIP")
                            continue

                    # ëª©í‘œ ê°œìˆ˜ ë„ë‹¬ ì‹œ ì¢…ë£Œ
                    if self.product_count and collected_count >= self.product_count:
                        break

                    if self.should_stop:
                        break

                    # ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ â†’ ìŠ¤í¬ë¡¤í•˜ì—¬ ë‹¤ìŒ ë°°ì¹˜ ë¡œë“œ
                    if batch_end >= current_total:
                        # ëª¨ë“  ë³´ì´ëŠ” ìƒí’ˆì„ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ìŠ¤í¬ë¡¤
                        print(f"\n[ë°°ì¹˜ {batch_num}] ì™„ë£Œ â†’ ìŠ¤í¬ë¡¤í•˜ì—¬ ë‹¤ìŒ {batch_size}ê°œ ë¡œë“œ...")
                        before_scroll = current_total
                        await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                        await asyncio.sleep(3)  # ë¡œë”© ëŒ€ê¸°

                        # ìŠ¤í¬ë¡¤ í›„ ìƒí’ˆ ê°œìˆ˜ í™•ì¸
                        product_links_after = await page.query_selector_all('a[class*="ProductCard_link"]')
                        after_scroll = len(product_links_after)

                        scroll_count += 1

                        if after_scroll > before_scroll:
                            print(f"[ìŠ¤í¬ë¡¤ #{scroll_count}] {before_scroll}ê°œ â†’ {after_scroll}ê°œ (ìƒˆë¡œ ë¡œë“œ: {after_scroll - before_scroll}ê°œ)")
                        else:
                            print(f"\në” ì´ìƒ ìƒˆ ìƒí’ˆì´ ë¡œë“œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìˆ˜ì§‘ ì¢…ë£Œ.")
                            break
                    else:
                        # ì•„ì§ ì²˜ë¦¬í•  ìƒí’ˆì´ ë‚¨ìŒ (ìŠ¤í¬ë¡¤ ë¶ˆí•„ìš”)
                        print(f"[ë°°ì¹˜ {batch_num}] ì²˜ë¦¬ ì™„ë£Œ - ë‹¤ìŒ ë°°ì¹˜ë¡œ ì§„í–‰")
                        continue

                # ìµœì¢… í…Œì´ë¸” ì¶œë ¥ (50ì˜ ë°°ìˆ˜ê°€ ì•„ë‹Œ ê²½ìš°)
                if len(self.products_data) % 50 != 0:
                    self._print_products_table(len(self.products_data), final=True)
                else:
                    print(f"\n\nìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(self.products_data)}ê°œ â†’ DB ì €ì¥ë¨")

            finally:
                # DB ì—°ê²° ì¢…ë£Œ
                if self.db_connected and self.db:
                    try:
                        self.db.close()
                        print("[DB] ì—°ê²° ì¢…ë£Œ")
                    except:
                        pass
                await browser.close()

            return self.products_data

    def _print_products_table(self, count: int, final: bool = False):
        """50ê°œ ë‹¨ìœ„ë¡œ ìˆ˜ì§‘ëœ ëª¨ë“  ìƒí’ˆ ì •ë³´ë¥¼ í…Œì´ë¸”ë¡œ ì¶œë ¥"""
        print("\n")  # ì§„í–‰ ë©”ì‹œì§€ ì¤„ë°”ê¿ˆ

        # í—¤ë”
        if final:
            print("=" * 61)
            print(f"{'[ì™„ë£Œ] ìˆ˜ì§‘ ì™„ë£Œ - ì „ì²´ ìƒí’ˆ ëª©ë¡':^55}")
            print("=" * 61)
        else:
            print("=" * 61)
            print(f"{'[ì§„í–‰ì¤‘] ìˆ˜ì§‘ í˜„í™© (' + str(count) + 'ê°œ ì™„ë£Œ)':^55}")
            print("=" * 61)

        # í†µê³„ ì •ë³´
        elapsed = time.time() - self.start_time
        elapsed_min = int(elapsed // 60)
        elapsed_sec = int(elapsed % 60)
        speed = count / (elapsed / 60) if elapsed > 0 else 0

        if self.save_to_db:
            print(f"  ì´ ìˆ˜ì§‘      : {count}ê°œ")
            print(f"  DB ì €ì¥      : {self.saved_count}ê°œ ({self.saved_count/count*100:.1f}%)")
            print(f"  ì¤‘ë³µ ìŠ¤í‚µ    : {self.skipped_count}ê°œ ({self.skipped_count/count*100:.1f}%)")
        else:
            print(f"  ì´ ìˆ˜ì§‘      : {count}ê°œ")

        # ê°€ê²© í†µê³„
        prices = [p.get('price') for p in self.products_data if p.get('price')]
        if prices:
            avg_price = sum(prices) / len(prices)
            min_price = min(prices)
            max_price = max(prices)
            print(f"  í‰ê·  ê°€ê²©    : {avg_price:,.0f}ì›")
            print(f"  ê°€ê²© ë²”ìœ„    : {min_price:,}ì› ~ {max_price:,}ì›")

        # ë¸Œëœë“œ/íƒœê·¸ í†µê³„
        brands = [p for p in self.products_data if p.get('brand_name')]
        tags = [p.get('search_tags', []) for p in self.products_data]
        avg_tags = sum(len(t) for t in tags) / len(tags) if tags else 0

        print(f"  ë¸Œëœë“œ ìˆ˜ì§‘  : {len(brands)}ê°œ ({len(brands)/count*100:.1f}%)")
        print(f"  íƒœê·¸ í‰ê·     : {avg_tags:.1f}ê°œ/ìƒí’ˆ")
        print(f"  ì†Œìš” ì‹œê°„    : {elapsed_min}ë¶„ {elapsed_sec}ì´ˆ")
        print(f"  ìˆ˜ì§‘ ì†ë„    : {speed:.1f}ê°œ/ë¶„")
        print("=" * 61)

        # ìƒí’ˆ í…Œì´ë¸”
        print("\n  # | ìƒí’ˆëª… (35ì)                      | ê°€ê²©      | ë¸Œëœë“œ     | íƒœê·¸ | DB ")
        print("-" * 61)

        # ë§ˆì§€ë§‰ 50ê°œ (ë˜ëŠ” ì „ì²´) ì¶œë ¥
        start_idx = max(0, len(self.products_data) - 50)
        for i, product in enumerate(self.products_data[start_idx:], start=start_idx + 1):
            name = product.get('product_name', 'N/A')[:35]
            price = product.get('price')
            price_str = f"{price:>6,}ì›" if price else "   N/A"
            brand = (product.get('brand_name') or '-')[:10]
            tags_count = len(product.get('search_tags', []))
            db_status = product.get('_db_status', 'none')

            # DB ìƒíƒœ ê¸°í˜¸ (ëª…í™•í•œ í‘œì‹œ)
            if db_status == 'saved':
                db_icon = 'OK'
            elif db_status == 'skipped':
                db_icon = 'DUP'
            elif db_status == 'error':
                db_icon = 'ERR'
            else:
                db_icon = 'N/A'

            print(f"{i:3d} | {name:35s} | {price_str} | {brand:10s} | {tags_count:2d}ê°œ | {db_icon:3s}")

        print("=" * 61)
        print()

    async def _collect_product_info(self, page) -> Optional[Dict]:
        """ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ (13ê°œ í•„ë“œ)"""
        data = {}

        try:
            # 1. product_id (URLì—ì„œ ì¶”ì¶œ)
            url = page.url
            match = re.search(r'/products/(\d+)', url)
            data['product_id'] = match.group(1) if match else None

            # 2. category_name
            data['category_name'] = self.category_name

            # 3. product_name
            elem = await page.query_selector('h3.DCVBehA8ZB')
            data['product_name'] = await elem.inner_text() if elem else None

            # 4. brand_name (í…Œì´ë¸”ì—ì„œ) - ìŠ¤í¬ë¡¤ ì—†ì´ ë°”ë¡œ ìˆ˜ì§‘
            brand_result = await page.evaluate('''() => {
                const allElements = document.querySelectorAll('td, th');
                for (let elem of allElements) {
                    const text = elem.textContent || '';
                    if (text.trim() === 'ë¸Œëœë“œ') {
                        const nextTd = elem.nextElementSibling;
                        if (nextTd) {
                            const brandValue = nextTd.textContent.trim();
                            if (brandValue && brandValue.length < 50) {
                                return brandValue;
                            }
                        }
                    }
                }
                return null;
            }''')
            data['brand_name'] = brand_result

            # 5. price
            elem = await page.query_selector('strong.Izp3Con8h8')
            if elem:
                price_text = await elem.inner_text()
                price_clean = re.sub(r'[^\d]', '', price_text)
                data['price'] = int(price_clean) if price_clean else None
            else:
                data['price'] = None

            # 6. discount_rate (JavaScript evaluate)
            discount_result = await page.evaluate('''() => {
                const allElements = document.querySelectorAll('*');
                for (let elem of allElements) {
                    const text = elem.textContent || '';
                    if (text.includes('%') && text.length < 20) {
                        const match = text.match(/(\\d+)%/);
                        if (match && elem.children.length <= 1) {
                            return match[1];
                        }
                    }
                }
                return null;
            }''')
            data['discount_rate'] = int(discount_result) if discount_result else None

            # 7. review_count
            review_result = await page.evaluate('''() => {
                const allElements = document.querySelectorAll('*');
                for (let elem of allElements) {
                    const text = elem.textContent || '';
                    if (text.includes('ë¦¬ë·°') && text.length < 20) {
                        const match = text.match(/ë¦¬ë·°\\s*(\\d+)/);
                        if (match) {
                            return match[1];
                        }
                    }
                }
                return null;
            }''')
            data['review_count'] = int(review_result) if review_result else 0

            # 8. rating
            rating_result = await page.evaluate('''() => {
                const allElements = document.querySelectorAll('*');
                for (let elem of allElements) {
                    const text = elem.textContent || '';
                    if ((text.includes('í‰ì ') || text.includes('ë³„ì ')) && text.length < 30) {
                        const match = text.match(/(\\d+\\.\\d+)/);
                        if (match) {
                            return parseFloat(match[1]);
                        }
                    }
                }
                return null;
            }''')
            data['rating'] = rating_result

            # 9. search_tags (ìµœì í™”: 2ë²ˆë§Œ ìŠ¤í¬ë¡¤)
            # 30% ìŠ¤í¬ë¡¤ (brand_name ìœ„ì¹˜)
            await page.evaluate('window.scrollTo(0, document.body.scrollHeight * 0.3)')
            await asyncio.sleep(1.5)

            # 50% ìŠ¤í¬ë¡¤ (search_tags ìœ„ì¹˜)
            await page.evaluate('window.scrollTo(0, document.body.scrollHeight * 0.5)')
            await asyncio.sleep(2.0)

            # íƒœê·¸ ìˆ˜ì§‘
            all_tags_found = set()
            all_links = await page.query_selector_all('a')
            for link in all_links:
                try:
                    text = await link.inner_text()
                    if text and text.strip().startswith('#'):
                        clean_tag = text.strip().replace('#', '').strip()
                        if 1 < len(clean_tag) < 30:
                            all_tags_found.add(clean_tag)
                except:
                    pass

            data['search_tags'] = list(all_tags_found)

            # 10. product_url
            data['product_url'] = url

            # 11. thumbnail_url
            elem = await page.query_selector('img[class*="image"]')
            data['thumbnail_url'] = await elem.get_attribute('src') if elem else None

            # 12, 13. íƒ€ì„ìŠ¤íƒ¬í”„
            now = datetime.now()
            data['crawled_at'] = now.isoformat()
            data['updated_at'] = now.isoformat()

            return data

        except Exception as e:
            print(f"   ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)[:50]}")
            return None


if __name__ == "__main__":
    async def test():
        crawler = SimpleCrawler(product_count=3, headless=False)
        products = await crawler.crawl()

        print("\n=== ìˆ˜ì§‘ ê²°ê³¼ ===")
        for i, p in enumerate(products, 1):
            print(f"{i}. {p.get('product_name', 'N/A')[:50]}")
            print(f"   ê°€ê²©: {p.get('price', 'N/A'):,}ì›")
            print(f"   ë¸Œëœë“œ: {p.get('brand_name', 'N/A')}")
            print(f"   íƒœê·¸: {len(p.get('search_tags', []))}ê°œ")

    asyncio.run(test())
