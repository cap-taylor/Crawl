"""ì¹´í…Œê³ ë¦¬ ê³„ì¸µ êµ¬ì¡° ì˜¬ë°”ë¥´ê²Œ ì¬ìˆ˜ì§‘

CRAWLING_LESSONS_LEARNED.md ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì¬ìˆ˜ì§‘:
- ëŒ€ë¶„ë¥˜: data-leaf="false"
- ì¤‘ë¶„ë¥˜: data-leaf í˜¼ì¬
- ì†Œë¶„ë¥˜: data-leaf="true" (ìµœì¢… ì¹´í…Œê³ ë¦¬)

í˜¸ë²„ ë°©ì‹ìœ¼ë¡œ ì„œë¸Œì¹´í…Œê³ ë¦¬ í‘œì‹œí•˜ì—¬ ìˆ˜ì§‘
"""
import asyncio
from playwright.async_api import async_playwright
import json
from pathlib import Path
import time

async def recollect_categories():
    """CRAWLING_LESSONS_LEARNED.md ê¸°ë°˜ ì˜¬ë°”ë¥¸ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘"""
    print("=" * 60)
    print("ë„¤ì´ë²„ í”ŒëŸ¬ìŠ¤ ìŠ¤í† ì–´ ì¹´í…Œê³ ë¦¬ ì¬ìˆ˜ì§‘ (ì˜¬ë°”ë¥¸ ë°©ë²•)")
    print("CRAWLING_LESSONS_LEARNED.md ë¬¸ì„œ ê¸°ë°˜")
    print("=" * 60)

    async with async_playwright() as p:
        # Firefox ì‚¬ìš© (ë¬¸ì„œì—ì„œ ì„±ê³µ í™•ì¸)
        print("\nğŸ¦Š Firefox ë¸Œë¼ìš°ì € ì‹¤í–‰...")
        browser = await p.firefox.launch(
            headless=False,  # ë°˜ë“œì‹œ False
            slow_mo=500      # ì²œì²œíˆ (ë´‡ ê°ì§€ íšŒí”¼)
        )

        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0",
            locale='ko-KR',
            timezone_id='Asia/Seoul'
        )

        page = await context.new_page()

        try:
            # 1. ë„¤ì´ë²„ ë©”ì¸ ì ‘ì†
            print("\nğŸ“ ë„¤ì´ë²„ ë©”ì¸ ì ‘ì† (ìº¡ì°¨ ì—†ìŒ)...")
            await page.goto("https://www.naver.com", wait_until="networkidle")
            print("âœ… ë„¤ì´ë²„ ë©”ì¸ ì ‘ì† ì„±ê³µ")
            await asyncio.sleep(3)

            # 2. ì‡¼í•‘ í´ë¦­ (ìƒˆ íƒ­)
            print("\nğŸ” ì‡¼í•‘ ë²„íŠ¼ ì°¾ëŠ” ì¤‘...")
            shopping_selector = '#shortcutArea > ul > li:nth-child(4) > a'
            shopping_link = await page.wait_for_selector(shopping_selector, timeout=10000)

            if shopping_link:
                print("ğŸ›ï¸ ì‡¼í•‘ í´ë¦­ (ìƒˆ íƒ­ì—ì„œ ì—´ë¦¼)...")
                # ìƒˆ íƒ­ ì´ë²¤íŠ¸ ê°ì§€
                async with context.expect_page() as new_page_info:
                    await shopping_link.click()

                shopping_page = await new_page_info.value
                await shopping_page.wait_for_load_state("networkidle")
                print(f"âœ… ì‡¼í•‘ í˜ì´ì§€ ì ‘ì† ì„±ê³µ: {shopping_page.url}")
                await asyncio.sleep(3)

                # 3. ì¹´í…Œê³ ë¦¬ ë²„íŠ¼ í´ë¦­
                print("\nğŸ“‚ ì¹´í…Œê³ ë¦¬ ë²„íŠ¼ í´ë¦­...")
                # ì—¬ëŸ¬ ë°©ë²• ì‹œë„
                category_button = None

                # ë°©ë²• 1: ì •í™•í•œ ì…€ë ‰í„° (CRAWLING_LESSONS_LEARNED.md)
                try:
                    category_button = await shopping_page.wait_for_selector(
                        '#gnb-gnb > div._gnb_header_area_nfFfz > div > div._gnbContent_gnb_content_JUwjU > div._gnbContent_button_area_FRBmE > div:nth-child(1) > button',
                        timeout=5000
                    )
                    print("  âœ“ ì •í™•í•œ ì…€ë ‰í„°ë¡œ ì°¾ìŒ")
                except:
                    pass

                # ë°©ë²• 2: í…ìŠ¤íŠ¸ë¡œ ì°¾ê¸°
                if not category_button:
                    try:
                        category_button = await shopping_page.wait_for_selector('button:has-text("ì¹´í…Œê³ ë¦¬")', timeout=5000)
                        print("  âœ“ í…ìŠ¤íŠ¸ë¡œ ì°¾ìŒ")
                    except:
                        pass

                # ë°©ë²• 3: aria-labelë¡œ ì°¾ê¸°
                if not category_button:
                    try:
                        category_button = await shopping_page.wait_for_selector('button[aria-label*="ì¹´í…Œê³ ë¦¬"]', timeout=5000)
                        print("  âœ“ aria-labelë¡œ ì°¾ìŒ")
                    except:
                        pass

                if category_button:
                    await category_button.click()
                    await asyncio.sleep(3)  # ë©”ë‰´ ì—´ë¦¬ê¸° ì¶©ë¶„íˆ ëŒ€ê¸°
                    print("âœ… ì¹´í…Œê³ ë¦¬ ë©”ë‰´ ì—´ë¦¼")

                    # ìŠ¤í¬ë¦°ìƒ· ì €ì¥ (ë””ë²„ê¹…ìš©)
                    project_root = Path(__file__).parent.parent.parent
                    data_dir = project_root / 'data'
                    data_dir.mkdir(exist_ok=True)
                    screenshot_path = data_dir / 'category_menu_open.png'
                    await shopping_page.screenshot(path=str(screenshot_path))
                    print(f"  ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_path}")
                else:
                    raise Exception("ì¹´í…Œê³ ë¦¬ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

                # 4. ëŒ€ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘
                print("\nğŸ” ëŒ€ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ ì¤‘...")

                # ì—¬ëŸ¬ ì…€ë ‰í„° ì‹œë„
                main_category_links = []

                # ë°©ë²• 1: í´ë˜ìŠ¤ ê¸°ë°˜
                main_category_links = await shopping_page.query_selector_all('._categoryLayer_link_8hzu')
                print(f"  ë°©ë²•1 (í´ë˜ìŠ¤): {len(main_category_links)}ê°œ")

                # ë°©ë²• 2: data-id ì†ì„± ê¸°ë°˜
                if not main_category_links:
                    main_category_links = await shopping_page.query_selector_all('a[data-id]')
                    print(f"  ë°©ë²•2 (data-id): {len(main_category_links)}ê°œ")

                # ë°©ë²• 3: ì¹´í…Œê³ ë¦¬ ë ˆì´ì–´ ë‚´ë¶€ ë§í¬
                if not main_category_links:
                    main_category_links = await shopping_page.query_selector_all('.categoryLayer a')
                    print(f"  ë°©ë²•3 (categoryLayer a): {len(main_category_links)}ê°œ")

                categories_data = {
                    "ìˆ˜ì§‘ì¼ì‹œ": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "í”Œë«í¼": "ë„¤ì´ë²„ í”ŒëŸ¬ìŠ¤ ìŠ¤í† ì–´",
                    "ê³„ì¸µêµ¬ì¡°": "ëŒ€ë¶„ë¥˜ > ì¤‘ë¶„ë¥˜ > ì†Œë¶„ë¥˜ (3ë‹¨ê³„)",
                    "ì¹´í…Œê³ ë¦¬": {}
                }

                main_count = 0
                sub_count = 0

                for idx, main_link in enumerate(main_category_links):
                    try:
                        # ëŒ€ë¶„ë¥˜ ì •ë³´ ì¶”ì¶œ
                        main_name = await main_link.text_content()
                        main_name = main_name.strip() if main_name else ""

                        if not main_name:
                            continue

                        main_id = await main_link.get_attribute('data-id')
                        main_leaf = await main_link.get_attribute('data-leaf')
                        main_url = await main_link.get_attribute('href')

                        print(f"\n  [{idx+1}] {main_name} (ID: {main_id}, leaf: {main_leaf})")

                        categories_data["ì¹´í…Œê³ ë¦¬"][main_name] = {
                            "id": main_id,
                            "url": main_url if main_url else f"https://search.shopping.naver.com/ns/category/{main_id}",
                            "data_leaf": main_leaf,
                            "level": 0,
                            "sub_categories": []
                        }
                        main_count += 1

                        # í•˜ìœ„ ì¹´í…Œê³ ë¦¬ê°€ ìˆìœ¼ë©´ í˜¸ë²„í•˜ì—¬ ìˆ˜ì§‘
                        if main_leaf == "false":
                            print(f"    ğŸ” {main_name} í•˜ìœ„ ì¹´í…Œê³ ë¦¬ í™•ì¸ ì¤‘...")
                            await main_link.hover()
                            await asyncio.sleep(1.5)  # ì„œë¸Œë©”ë‰´ ë¡œë”© ëŒ€ê¸°

                            # ì„œë¸Œì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ (ì˜¤ë¥¸ìª½ íŒ¨ë„)
                            sub_category_elements = await shopping_page.query_selector_all('span._categoryLayer_text_XOd4h')

                            collected_subs = set()  # ì¤‘ë³µ ë°©ì§€
                            for sub_elem in sub_category_elements:
                                sub_name = await sub_elem.text_content()
                                sub_name = sub_name.strip() if sub_name else ""

                                # í•„í„°ë§: "ë”ë³´ê¸°", ë¹ˆ ë¬¸ìì—´, ëŒ€ë¶„ë¥˜ì™€ ê°™ì€ ì´ë¦„ ì œì™¸
                                if sub_name and sub_name != main_name and "ë”ë³´ê¸°" not in sub_name:
                                    # ëŒ€ë¶„ë¥˜ ëª©ë¡ê³¼ ì¤‘ë³µë˜ëŠ”ì§€ í™•ì¸
                                    if sub_name not in categories_data["ì¹´í…Œê³ ë¦¬"]:
                                        if sub_name not in collected_subs:
                                            # ìƒìœ„ ë§í¬ ì°¾ê¸°
                                            parent_link = await sub_elem.evaluate_handle("el => el.closest('a')")
                                            if parent_link:
                                                sub_id = await parent_link.as_element().get_attribute('data-id')
                                                sub_leaf = await parent_link.as_element().get_attribute('data-leaf')
                                                sub_url = await parent_link.as_element().get_attribute('href')

                                                categories_data["ì¹´í…Œê³ ë¦¬"][main_name]["sub_categories"].append({
                                                    "name": sub_name,
                                                    "id": sub_id,
                                                    "url": sub_url,
                                                    "data_leaf": sub_leaf,
                                                    "level": 1
                                                })
                                                collected_subs.add(sub_name)
                                                sub_count += 1

                            print(f"    âœ… {len(collected_subs)}ê°œ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘")

                        # ê³¼ë„í•œ ìš”ì²­ ë°©ì§€
                        await asyncio.sleep(0.5)

                    except Exception as e:
                        print(f"    âŒ {main_name} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
                        continue

                # 5. ë°ì´í„° ì €ì¥
                categories_data["ëŒ€ë¶„ë¥˜ìˆ˜"] = main_count
                categories_data["ì „ì²´ì„œë¸Œì¹´í…Œê³ ë¦¬ìˆ˜"] = sub_count

                project_root = Path(__file__).parent.parent.parent
                data_dir = project_root / 'data'
                data_dir.mkdir(exist_ok=True)

                save_path = data_dir / 'naver_categories_hierarchy.json'
                with open(save_path, 'w', encoding='utf-8') as f:
                    json.dump(categories_data, f, ensure_ascii=False, indent=2)

                print(f"\n{'=' * 60}")
                print(f"âœ… ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ ì™„ë£Œ!")
                print(f"  â€¢ ëŒ€ë¶„ë¥˜: {main_count}ê°œ")
                print(f"  â€¢ ì „ì²´ ì„œë¸Œì¹´í…Œê³ ë¦¬: {sub_count}ê°œ")
                print(f"  â€¢ ì €ì¥ ìœ„ì¹˜: {save_path}")
                print(f"{'=' * 60}")

            else:
                print("âŒ ì‡¼í•‘ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

            # 10ì´ˆ ëŒ€ê¸°
            print("\nğŸ‘€ 10ì´ˆ í›„ ë¸Œë¼ìš°ì € ì¢…ë£Œ...")
            await asyncio.sleep(10)

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()

        finally:
            await browser.close()
            print("ğŸ”š ë¸Œë¼ìš°ì € ì¢…ë£Œ")

if __name__ == "__main__":
    asyncio.run(recollect_categories())
